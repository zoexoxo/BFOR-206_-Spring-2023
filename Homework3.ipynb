{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scanning Reddit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1\n",
    "### I'll have my bot randomly choose a post or comment to respond to or answer prompts or comments/posts that I tell it to respond to"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 \n",
    "### The bot would respond to posts like if someone posts a question the bot would accurately respond to the post. And/or agree or disagree to a comment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 \n",
    "### Yes, I have checked my bot's post history to avoid duplicate posts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a bot to generate a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APP_ID:\t\t eCllrt67mhOE_1bCkwr2sg\n",
      "API_SECRET:\t 4DxrtylHHS8B8wcYoIejpEVlkN3Ijw\n",
      "Running GPT bot\n",
      "Successful app authentification True\n",
      "Prompt:  We went from video games having 0 micro transactions to games built off them and now car companies are doing monthly service add ons for a fee , what’s next that people don’t see coming ?\n",
      "Response:  {\n",
      "  \"content\": \"As an AI language model, I cannot accurately predict the future. However, there are ongoing discussions on the possibility of subscription-based models for certain industries such as healthcare, education, and even government services. It remains to be seen if these ideas will be fully implemented, but it is something to watch out for in the future.\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#This script will be used to send prompts to the \n",
    "#GPT API and post the replies to reddit.\n",
    "\n",
    "# %% imports\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import git_reddit_posts as grp\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# store API credntials\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ.get('OPEN_AI')\n",
    "openai.Model.list()\n",
    "\n",
    "def find_relevant_posts(submissions_df):\n",
    "\n",
    "  \n",
    "\n",
    "  #Find posts that seem good to respond to.\n",
    "  #You can adjust your criteria to choose what you like.\n",
    "  #This could be based on score, keywords, etc.\n",
    "\n",
    "  # sort by newest\n",
    "  top_post = submissions_df.sort_values(by='created_utc',ascending=False).head(1)\n",
    "\n",
    "  return top_post\n",
    "\n",
    "def prompt_gpt(prompt: str):\n",
    "\n",
    "  #Generate a response to a prompt\n",
    "\n",
    "  completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "  return completion.choices[0].message\n",
    "\n",
    "def has_ai_language(response: str) -> bool:\n",
    "  #This function will check if the response contains the \"As an AI launguage model\" disclaimer\n",
    "\n",
    "  check_string = \"as an AI language model\".lower()\n",
    "\n",
    "  if check_string in response.lower():\n",
    "    return True\n",
    "  \n",
    "  else:\n",
    "    return False\n",
    "  \n",
    "  # check ai language function\n",
    "\n",
    "def test_has_ai_language():\n",
    "\n",
    "  assert True == has_ai_language(\"As an AI language model, I don't have personal opinons.\")\n",
    "  assert False == has_ai_language(\"I don't have personal opinons,\")\n",
    "\n",
    "def update_post_history(post_id: str, history_file: str):\n",
    "  #This function will uodate the post hsitory with the post that was responded to\n",
    "  #If the post id is already in the file\n",
    "\n",
    "\n",
    "  #check for post id in file\n",
    "  with open(history_file, 'r') as f:\n",
    "    post_ids = f.readlines()\n",
    "\n",
    "  #check if post id is in file\n",
    "  if post_id in post_ids:\n",
    "    print(\"Post has already been responded to\")\n",
    "    return True\n",
    "  \n",
    "  #add post id to file\n",
    "  with open(history_file, 'a') as f:\n",
    "    f.write(post_id + '\\n')\n",
    "    return False\n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "#%% main\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  print('Running GPT bot')\n",
    "\n",
    "  reddit = grp.reddit_connection()\n",
    "\n",
    "  #get posts\n",
    "  submissions = reddit.subreddit('AskReddit').hot(limit=5)\n",
    "  \n",
    "  # this function is a simpler version of what we had earlier\n",
    "  submissions_df = grp.create_submission_df(submissions)\n",
    "\n",
    "  top_post = find_relevant_posts(submissions_df)\n",
    "  \n",
    "  # check if there are any post to respond to\n",
    "  for index, submission in top_post.iterrows():\n",
    "    print\n",
    "\n",
    "  \n",
    "  prompt = top_post['title'].values[0]\n",
    "  \n",
    "  response = prompt_gpt(prompt)\n",
    "  \n",
    "  print(\"Prompt: \", prompt)\n",
    "  \n",
    "  print(\"Response: \", response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Post History"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Bot on a Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Statistics about your Bot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\n",
    "### "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\n",
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\n",
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\n",
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\n",
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.\n",
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
